
## 关于Parser编译时引用出错问题。

记： 一个简单但是很隐蔽的问题。出于对旧代码的过度信任和对新旧代码的差异感知不敏锐。。

parser编译时有一个去重优化:

在旧版本EBNFParser中，由于任意的模式组合子都有一个和功能一一对应的名字,例如

```bnf
S ::= ('a' 'b' 'c')*;
```

这其中, S的名字就是S自己，但是这个模式中还有其他隐式生成的模式.
'a' 'b' 'c'三者本身各是一个字面量模式，分别能够parse一个单字符，而('a' 'b' 'c')*则是一个新的pattern, 它顺序组合了'a' 'b' 'c'，
并可以进行0到无穷次这样的序列的匹配。

在上述的描述中，当我提到一个'a'我们必然知道它是用来parse 'a'的一个模式，而所以这样的模式我们可以给它唯一的名字，
同时，像解析('a' 'b' 'c')*这样语法的组合模式，我们就可以用它的bnf描述来唯一表征具有这样功能的模式。
这样一来，ebnfparser在经过编译后，可以大量的减少内存开销。

但现在，当新的ebnfparser在使用了一种加速parsing的策略时，遭遇了一个问题。

我们先来看一下现在的ebnfparser做了什么事情。

首先我们定义一组同名(但匹配的字符串不同，且均为常量字符串)tokenizer, 它会同时生成对应的literal匹配模式。

```bnf
keyword := 'abcd' 'efgh'; # 定义一组同名token
```

然后定义一个parser
```bnf

/*
定义一个组合的匹配模式
*/
S ::= ('a' 'b' 'c')*; 
```
把上面的ruiko ebnf代码写到一个文件里，然后编译一下, 并生成快捷测试语法的脚本。

```shell
ruiko grammar.ruiko compiling_ref1.py --test
```

生成如下文件

- compiling_ref1.py
- test_lang.py

主要看一下前者干了什么，也就是parser和token都是什么样的。

- compiling_ref.py
```python
# This file is automatically generated by EBNFParser.
from Ruikowa.ObjectRegex.Tokenizer import unique_literal_cache_pool, regex_matcher, char_matcher, str_matcher, Tokenizer
from Ruikowa.ObjectRegex.Node import AstParser, Ref, SeqParser, LiteralValueParser, LiteralNameParser, Undef
namespace = globals()
recur_searcher = set()
token_table = ((unique_literal_cache_pool["keyword"], str_matcher(('efgh', 'abcd'))),
               (unique_literal_cache_pool["auto_const"], char_matcher(('c', 'b', 'a'))))

class UNameEnum:
# names
    auto_const = unique_literal_cache_pool['auto_const']
    keyword = unique_literal_cache_pool['keyword']
    S = unique_literal_cache_pool['S']
# values
    auto_const_c = unique_literal_cache_pool['c']
    keyword_efgh = unique_literal_cache_pool['efgh']
    auto_const_a = unique_literal_cache_pool['a']
    auto_const_b = unique_literal_cache_pool['b']
    keyword_abcd = unique_literal_cache_pool['abcd']
        
token_func = lambda _: Tokenizer.from_raw_strings(_, token_table, ({}, {}))
keyword = LiteralNameParser('keyword')
S = AstParser([SeqParser(['a', 'b', 'c'], at_least=0,at_most=Undef)],
              name="S",
              to_ignore=({}, {}))
S.compile(namespace, recur_searcher)
```

这个时候，看一下token_table, 没有问题，单字符串会使用适用单字符的token策略，常量字符串会使用适用常量字符串的token策略。这都没有问题。问题在于生成的匹配模式(parser).

让我们parser genenertor生成的代码里加一行，打印一下模式`S`里那个parse`('a' 'b' 'c')*`的东西的名字。
```python
S = AstParser([SeqParser(['a', 'b', 'c'], at_least=0,at_most=Undef)],
              name="S",
              to_ignore=({}, {}))
S.compile(namespace, recur_searcher)

# add here
print (S.possibilities[0][0].name)
```

运行一下这个文件

```shell
python compiling_ref1.py
(a b c)*
```

额，这个是修正了bug的版本，以前是这样的

```shell
python compiling_ref1.py
(auto_const auto_const auto_const)*
```

记住这个名字`(auto_const auto_const auto_const)*`以及记住我们之前说的, ebnfparser将ebnf源码作为名字来表征parser的功能。(当前可用的ebnfparser已经解决这个问题，此处是记录一个开发中曾被忽略后来导致巨大消耗的问题。

`AstParser`进行构造时，如果是以前的ebnfparser, 里面的字符串会进行如下处理。

[Node.py line 82-103](https://github.com/thautwarm/EBNFParser/blob/boating-new/Python/Ruikowa/ObjectRegex/Node.py)
```python

class AstParser(BaseParser):

    def __init__(self, *ebnf, name=Undef, to_ignore=Undef):
        # each in the cache will be processed into a parser.
        ebnf = tuple(
            tuple(
                LiteralValueParser(unique_literal_cache_pool['auto_const'],
                                   unique_literal_cache_pool[each]) if isinstance(each, str) else each
                for each in p)
            for p in ebnf)
        self.cache = optimize(ebnf)

        # the possible output types for an series of input tokenized words.
        self.possibilities = []

        # whether this parser will refer to itself.
        self.has_recur = False

        # the identity of a parser.
        self.name = name if name is not Undef else \
            ' | '.join(
                ' '.join(map(lambda parser: parser.name,
                             ebnf_i)) for ebnf_i in ebnf)
        ...

```

`unique_literal_cache_pool`的`__getitem__`元方法接受一个字符串传入，**返回一个值完全相同的字符串**。但是有一个好的性质，对于相同的键值，返回的字符串是确凿无疑的同一个对象，也就是可以**使用`is`来比较常量字符串或者Tokenizer的名字是否相等**，这是新的ebnfparser速度骤升的主要原因之一。我们，不再在parser的时候花费时间去进行常量字符串的值比较甚至是正则匹配。

但是，请注意,  对于隐式生成的parser, `self.name`的生成用到了内部token的名字，但是这个名字不是唯一的。所有的隐式常量字符串，都将分配固定的名字，`auto_const`, 于是乎，compile的时候，可能会出错。

上面已经说了, compile的目的之一时去重，还有一个目的就是找出所有的可能递归调用自己的parser, 并且给他们一个属性`has_recur=True`.



见[Node.py line 111-198](https://github.com/thautwarm/EBNFParser/blob/boating-new/Python/Ruikowa/ObjectRegex/Node.py)
此处摘选关键代码
```python
for es in self.cache:
    self.possibilities.append([])

    for e in es:
        ...
        elif e.__class__ is Ref:  # Reference of LiteralNameParser, AstParser and Seqparser
            unique_lit_name(e)

            e = namespace[e.name]

            if e.__class__ not in LiteralParsers:
                e.compile(namespace, recur_searcher)

            self.possibilities[-1].append(e)

            if not self.has_recur and e.has_recur:
                self.has_recur = True
        else:  # AstParser or SeqParser
            unique_lit_name(e)
            if e.name not in namespace:
                namespace[e.name] = e
            else:
                e = namespace[e.name]

            e.compile(namespace, recur_searcher)
            self.possibilities[-1].append(e)

            if not self.has_recur and e.has_recur:
                self.has_recur = True
        ...
```
好了，你看，它从一个叫`namespace`的东西里，通过名字取出一个通过名字进行匹配的literal parser或者是复合的显式或者隐式parser。  

通常来说，`namespace`就直接是`globals()`，而`self.name`就是这个对象在当前模块里的名字。

好了，我们看上面叫做`S`的组合parser, 它的一个元素是`(auto_const auto_const auto_const)*`, 加入这个时候我再定一个新的组合parser叫

```bnf
F ::= ('g' 'e' 'h')* 'i' 'j' 'k';
```

很遗憾，在编译的时候`('a' 'b' 'c')*`和`('g' 'e' 'h')*`都是`(auto_const auto_const auto_const)*`。

所以做了修正，考虑到隐式组合parser的名字重复问题时，我们使用如下规则定义组合parser的名字。

```python

self.name = name if name is not Undef else \
            ' | '.join(
                ' '.join(map(lambda parser: parser.mode if parser.__class__ is LiteralValueParser else parser.name,
                             ebnf_i)) for ebnf_i in ebnf)

```
